---
layout: post
title:  "KAN 모델을 활용한 CO2RR 공정 데이터 분석"
date:   2025-07-27 16:00:00 +0900
categories: [AI, KAN, DataAnalysis]
tags: [Python, Jupyter, MachineLearning, CO2RR]
---





### {#16d46561 .cell .markdown}
MLP 이용 간단한 ANN을 만들어서 데이터석 진행 (KAN 비교용)
###

### {#52bae892 .cell .markdown}
step1. Excel 데이터 가져오기
###

### {#c183e714 .cell .code execution_count="1"}
``` python
# 엑셀 데이터 로드 
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import os


file_path = "25.01.14_CO2RR_GSA.xlsx"

if not os.path.exists(file_path):
    raise FileNotFoundError(f"파일을 찾을 수 없습니다: {file_path}")

xls = pd.ExcelFile("25.01.14_CO2RR_GSA.xlsx") # file_path 변수 실제 활용
X  = pd.read_excel(xls, sheet_name='Input')
df_out = pd.read_excel(xls, sheet_name='Output')

Y = df_out[['MSP ($/kgCO)']]  # MSP ($/kgCO)  # Required energy_total (MJ/kgCO)





```
###

### {#2e394217 .cell .markdown}
step2. 데이터 분리 및 스케일링 \_ 여기서는 평균 0 표준편차 1로
스케일링함
###

### {#bee59db7 .cell .code execution_count="2"}
``` python
# 1차 분할 (test 분리)
X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)
# 2차 분할(train, valid 분리)
X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size=0.2, random_state=42)

# train:valid:test = 64:16:20

# 데이터 스케일링(표준화)(평균, 표준편차 이용)

# **중요** : 스케일러는 반드시 *훈련 데이터(X_train)*에만 fit 해야한다. 그래야 valid나 test 데이터의 정보가 누출될 위험을 줄인다

scaler_X = StandardScaler()
X_train_scaled = scaler_X.fit_transform(X_train)  # X_train 데이터를 이용해 scaler_X.transform을 학습 + X_train_scaled 반환
X_val_scaled = scaler_X.transform(X_val) # train 데이터로 학습한 scaler_X.transform 함수로 다른 것들도 학습
X_test_scaled = scaler_X.transform(X_test) 

scaler_Y = StandardScaler()
Y_train_scaled = scaler_Y.fit_transform(Y_train)  # Y_train 데이터를 이용해 scaler_Y.transform을 학습 + Y_train_scaled 반환
Y_val_scaled = scaler_Y.transform(Y_val)
Y_test_scaled = scaler_Y.transform(Y_test)

# 분리한 결과 어떻게 나오는지 확인해보기

print("\n--- 데이터 분할 및 전처리 최종 결과 ---")
print(f"훈련 데이터 형태: X({X_train_scaled.shape}), Y({Y_train_scaled.shape})")
print(f"검증 데이터 형태: X({X_val_scaled.shape}), Y({Y_val_scaled.shape})")
print(f"테스트 데이터 형태: X({X_test_scaled.shape}), Y({Y_test_scaled.shape})")

print("\n\n 스케일링된 훈련 데이터(X_train_scaled) 샘플:")
print(pd.DataFrame(X_train_scaled, columns=X_train.columns).head())  
# .head()는 첫번째 5줄만 출력 , numpy 배열은 컬럼명이 없어 데이터 구조가 한눈에 파악하기 어렵다. 
# 그래서 pd.DataFrame(..., columns=...)을 이용하면, 스케일링된 데이터를 원래 컬럼명과 함께 보기 좋게 pandas DataFrame으로 변환 이용
```

### {.output .stream .stdout}

    --- 데이터 분할 및 전처리 최종 결과 ---
    훈련 데이터 형태: X((1600, 8)), Y((1600, 1))
    검증 데이터 형태: X((400, 8)), Y((400, 1))
    테스트 데이터 형태: X((501, 8)), Y((501, 1))


     스케일링된 훈련 데이터(X_train_scaled) 샘플:
       Current density (mA/cm2)  Faradaic efficiency (%)  CO coversion  \
    0                  1.441673                 0.360241      0.532953   
    1                 -0.926417                -1.171090     -0.246477   
    2                  0.172068                 0.046016     -1.299123   
    3                 -0.875356                -0.994082      1.391436   
    4                  1.623833                -1.276747      1.126541   

       Voltage (V)  Electricity cost ($/kWh)  Membrain cost ($/m2)  \
    0    -0.358187                  1.459581             -0.498390   
    1     0.537111                  0.955127              1.237291   
    2     1.189616                  0.946880             -1.165533   
    3    -0.278176                 -1.075060             -0.520536   
    4     0.286041                 -0.100515             -1.697034   

       Catpure energy (GJ/ton)  Crossover rate  
    0                 0.813698        1.450541  
    1                 1.564214        1.714248  
    2                 0.591017        1.447794  
    3                -0.795925        0.243260  
    4                 0.755966        1.473890  
###
###

### {#c5bbed48 .cell .markdown}
step3. MLP(ANN) 구조 설계 및 여러 신경망 층 구조에 대한 GridSearchCV
진행을 통해 최적 구조 찾기
###

### {#95c2444b .cell .code}
``` python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Dense
from scikeras.wrappers import KerasRegressor  # scikeras 권장
from sklearn.model_selection import GridSearchCV








# 1. 모델 생성 함수 / units1 = 은닉층 1층 / units2 = 은닉층2층
def create_ann_model(units1=32, units2=16, activation='relu'):
    model = Sequential([
        Input(shape=(8,)),             # 입력 특성 8개
        Dense(units1, activation=activation),
        Dense(units2, activation=activation),
        Dense(1, activation='linear')
    ])
    model.compile(
        optimizer='adam',
        loss='mean_squared_error',
        metrics=['mean_absolute_error']
    )
    return model


# 2. 래퍼 정의 (scikeras)
regressor = KerasRegressor(
    model=create_ann_model,    # 반드시 함수명만!
    verbose=0                  # fit epoch 로그 감춤
)



# 3. 모델 생성 및 구조 확인
# Required energy_total 예측 모델
#ann_model = create_ann_model()

# 모델의 구조를 요약하여 출력합니다.
#print("--- 'Required energy_total' 예측 모델 구조 ---")
#ann_model.summary()




# 3. GridSearch를 위한 파라미터 그리드 정의
param_grid = {
    'model__units1': [16, 32],      # 첫 은닉층 뉴런수 (은닉층1)
    'model__units2': [8, 16],       # 두 번째 은닉층 뉴런수 (은닉층2)
    'model__activation': ['relu', 'tanh'],
    'batch_size': [32],             # 배치 사이즈
    'epochs': [100],               # 학습 epoch 수 --- 50,100 이렇게 쓰기
}




# 4. GridSearchCV 객체 생성
grid = GridSearchCV(
    estimator=regressor,
    param_grid=param_grid,
    cv=3,                              # 3-fold 교차검증
    scoring='neg_mean_squared_error',  # MSE가 낮을수록 좋으니 음수로 반환
    n_jobs=-1
)

# 5. 학습 (여기서 Y_train_scaled.shape = (n_samples, 1)여야 함)
# scikit-learn의 GridSearchCV는 numpy array (2D 권장)
grid_result = grid.fit(X_train_scaled, Y_train_scaled)


# 6. 결과 출력
print("최적 하이퍼파라미터:", grid_result.best_params_)
print("최적 평균 검증 MSE:", -grid_result.best_score_)




# 7. 최적 파라미터 추출 / best_params에 다 저장이 되어있다
best_params = grid_result.best_params_
optimal_units1 = best_params['model__units1']
optimal_units2 = best_params['model__units2'] 
optimal_activation = best_params['model__activation']
optimal_batch_size = best_params['batch_size']


# GridSearchCV 결과 시각화
cv_results = pd.DataFrame(grid_result.cv_results_)
print("\n=== GridSearchCV 상세 결과 ===")
print(cv_results[['params', 'mean_test_score', 'std_test_score']].sort_values('mean_test_score', ascending=False))



# 8. 최적 파라미터로 모델 생성
def create_optimal_model():
    model = Sequential([
        Input(shape=(8,)),
        Dense(optimal_units1, activation=optimal_activation),
        Dense(optimal_units2, activation=optimal_activation),
        Dense(1, activation='linear')
    ])
    model.compile(
        optimizer='adam',
        loss='mean_squared_error',
        metrics=['mean_absolute_error']
    )
    return model

ann_model = create_optimal_model()

# 9. 최적 모델 구조 보여주기
print(f"최적 모델 구조:8- {optimal_units1}-{optimal_units2}, activation: {optimal_activation}, -1")




# 7. (선택) 결과 table을 보기 좋게 정리
#import pandas as pd
#cv_results = pd.DataFrame(grid_result.cv_results_)
#display(cv_results.sort_values('mean_test_score', ascending=False))
```

### {.output .stream .stdout}
최적 하이퍼파라미터: {'batch_size': 32, 'epochs': 100, 'model__activation': 'tanh', 'model__units1': 32, 'model__units2': 16}
최적 평균 검증 MSE: 0.10151575571815137

    === GridSearchCV 상세 결과 ===
                                                  params  mean_test_score  \
    7  {'batch_size': 32, 'epochs': 100, 'model__acti...        -0.101516   
    6  {'batch_size': 32, 'epochs': 100, 'model__acti...        -0.109080   
    4  {'batch_size': 32, 'epochs': 100, 'model__acti...        -0.141743   
    2  {'batch_size': 32, 'epochs': 100, 'model__acti...        -0.154954   
    3  {'batch_size': 32, 'epochs': 100, 'model__acti...        -0.169103   
    1  {'batch_size': 32, 'epochs': 100, 'model__acti...        -0.172488   
    5  {'batch_size': 32, 'epochs': 100, 'model__acti...        -0.172505   
    0  {'batch_size': 32, 'epochs': 100, 'model__acti...        -0.187275   

       std_test_score  
    7        0.022988  
    6        0.017376  
    4        0.025751  
    2        0.030629  
    3        0.036286  
    1        0.031335  
    5        0.047959  
    0        0.062227  
    최적 모델 구조:8- 32-16, activation: tanh, -1
###
###

### {#d0f297a0 .cell .markdown}
step4. MLP(ANN) 모델 컴파일
:::

::: {#b385cc74 .cell .raw vscode="{\"languageId\":\"raw\"}"}
```{=ipynb}
# 1. 모델 컴파일
# 모델이 어떻게 학습할지 학습 과정을 설정합니다.
ann_model.compile(
    optimizer='adam',
    loss='mean_squared_error',
    metrics=['mean_absolute_error']
)

# 2. 컴파일 완료 확인
print("--- 모델 컴파일 완료 ---")
print("최적화 알고리즘 (Optimizer): Adam")
print("손실 함수 (Loss Function): Mean Squared Error (MSE)")
print("평가 지표 (Metrics): Mean Absolute Error (MAE)")

# 컴파일 후 모델 구조를 다시 한번 확인하여 최종 상태를 볼 수 있습니다.
# 이 summary()는 컴파일 전과 내용은 동일하지만, 컴파일이 성공적으로 끝났음을 확인하는 의미가 있습니다.
print("\n컴파일된 모델의 최종 구조:")
ann_model.summary()
```
:::

::: {#8257c269 .cell .markdown}
step4. 모델 학습 및 plot
:::

::: {#97e2c920 .cell .code execution_count="4"}
``` python
# 1. 필요한 라이브러리 불러오기
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import r2_score
from tensorflow.keras.callbacks import EarlyStopping







# 2. 모델 학습 (Training)
print("--- 모델 학습을 시작합니다 ---")

early_stopping = EarlyStopping(
    monitor='val_loss',         # 검증 손실 기준
    patience=20,                # 개선되지 않는 epoch 10회 동안 기다리기(8~20 추천)
    restore_best_weights=True   # 가장 좋은 가중치로 복원
)


history = ann_model.fit(
    X_train_scaled, 
    Y_train_scaled,
    epochs=1000, #충분히 큰 값으로 설정
    batch_size=optimal_batch_size, #  # GridSearchCV 결과 활용
    validation_data=(X_val_scaled, Y_val_scaled),
    callbacks=[early_stopping],  # 콜백 추가 / overfitting 뜨기 전에 끊기
    verbose=1 # 학습 진행 로그를 상세하게 출력. (=에포크마다 손실/평가지표가 콘솔에 실시간 표시됨)
)
print("\n--- 모델 학습 완료 ---")









# 3. 모델 성능 평가 (Evaluation)
print("\n--- 테스트 데이터로 모델 성능을 평가합니다 ---")
test_loss, test_mae = ann_model.evaluate(X_test_scaled, Y_test_scaled, verbose=0)
print(f"테스트 데이터 손실 (MSE): {test_loss:.4f}")
print(f"테스트 데이터 평균 절대 오차 (MAE): {test_mae:.4f}")




# 4. 테스트 데이터 예측 및 R² 계산
Y_pred_scaled = ann_model.predict(X_test_scaled)
Y_pred = scaler_Y.inverse_transform(Y_pred_scaled)
Y_test_true = Y_test.values            # DataFrame에서 numpy로 변환

r2 = r2_score(Y_test_true, Y_pred)
print(f"테스트 데이터 결정계수 (R²): {r2:.4f}")

best_epoch = np.argmin(history.history['val_loss']) + 1  # 1-base
print(f"최적의 epoch: {best_epoch}")
print(f"최소 val_loss: {history.history['val_loss'][best_epoch-1]:.5f}")



# 5. 학습 과정 시각화 (Loss, MAE, R²)
fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(21, 5))

# Loss
ax1.plot(history.history['loss'], label='Training Loss')
ax1.plot(history.history['val_loss'], label='Validation Loss')
ax1.set_title('Loss (MSE)')
ax1.set_xlabel('Epoch'); ax1.set_ylabel('Loss'); ax1.legend(); ax1.grid(True)

# MAE
ax2.plot(history.history['mean_absolute_error'], label='Training MAE')
ax2.plot(history.history['val_mean_absolute_error'], label='Validation MAE')
ax2.set_title('Mean Absolute Error (MAE)')
ax2.set_xlabel('Epoch'); ax2.set_ylabel('MAE'); ax2.legend(); ax2.grid(True)

# R² 수기계산(별도 그래프)
ax3.plot([r2]*len(history.history['loss']), label=f'Test R² = {r2:.3f}')
ax3.set_title('Test R-squared')
ax3.set_xlabel('Epoch'); ax3.set_ylabel('R²'); ax3.legend(); ax3.grid(True)
ax3.set_ylim(bottom=0, top=1)

plt.tight_layout()
plt.show()




# 6. 실제값-예측값 산점도
plt.figure(figsize=(7,7))
plt.scatter(Y_test_true, Y_pred, alpha=0.5)
plt.plot([Y_test_true.min(), Y_test_true.max()],
         [Y_test_true.min(), Y_test_true.max()], 'r--', lw=2, label='Perfect')
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title(f"Actual vs. Predicted (R² = {r2:.3f})")
plt.legend(); plt.grid(True); plt.axis('equal')
plt.show()




# 7. 잔차 플롯 (residuals)
residuals = (Y_test_true.flatten() - Y_pred.flatten())
plt.figure(figsize=(8,6))
plt.scatter(Y_pred, residuals, alpha=0.6)
plt.axhline(0, color='red', linestyle='--')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals (Actual - Predicted)')
plt.title('Residual Plot')
plt.grid(True)
plt.show()


# 모델 성능 요약 
print(f"\n=== 최종 모델 성능 요약 ===")
print(f"모델 구조: 8-{optimal_units1}-{optimal_units2}-1")
print(f"활성화 함수: {optimal_activation}")
print(f"최적 epoch: {best_epoch}")
print(f"테스트 R²: {r2:.4f}")
print(f"테스트 MAE: {test_mae:.4f}")

```

::: {.output .stream .stdout}
    --- 모델 학습을 시작합니다 ---
    Epoch 1/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 0.9878 - mean_absolute_error: 0.6284 - val_loss: 0.5955 - val_mean_absolute_error: 0.4301
    Epoch 2/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.5015 - mean_absolute_error: 0.4289 - val_loss: 0.5824 - val_mean_absolute_error: 0.4359
    Epoch 3/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.5682 - mean_absolute_error: 0.4419 - val_loss: 0.5814 - val_mean_absolute_error: 0.4269
    Epoch 4/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.6200 - mean_absolute_error: 0.4420 - val_loss: 0.5720 - val_mean_absolute_error: 0.4264
    Epoch 5/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.4949 - mean_absolute_error: 0.4266 - val_loss: 0.5727 - val_mean_absolute_error: 0.4399
    Epoch 6/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.5498 - mean_absolute_error: 0.4413 - val_loss: 0.5706 - val_mean_absolute_error: 0.4246
    Epoch 7/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.5429 - mean_absolute_error: 0.4434 - val_loss: 0.5759 - val_mean_absolute_error: 0.4291
    Epoch 8/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.4695 - mean_absolute_error: 0.4105 - val_loss: 0.5590 - val_mean_absolute_error: 0.4356
    Epoch 9/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.5697 - mean_absolute_error: 0.4391 - val_loss: 0.5594 - val_mean_absolute_error: 0.4293
    Epoch 10/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.4745 - mean_absolute_error: 0.4131 - val_loss: 0.5531 - val_mean_absolute_error: 0.4338
    Epoch 11/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.5297 - mean_absolute_error: 0.4415 - val_loss: 0.5520 - val_mean_absolute_error: 0.4217
    Epoch 12/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.5709 - mean_absolute_error: 0.4212 - val_loss: 0.5626 - val_mean_absolute_error: 0.4040
    Epoch 13/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.4689 - mean_absolute_error: 0.3913 - val_loss: 0.5398 - val_mean_absolute_error: 0.4236
    Epoch 14/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.4554 - mean_absolute_error: 0.4049 - val_loss: 0.5388 - val_mean_absolute_error: 0.4143
    Epoch 15/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.5006 - mean_absolute_error: 0.4088 - val_loss: 0.5380 - val_mean_absolute_error: 0.4233
    Epoch 16/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.4813 - mean_absolute_error: 0.4027 - val_loss: 0.5307 - val_mean_absolute_error: 0.4064
    Epoch 17/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.4940 - mean_absolute_error: 0.4073 - val_loss: 0.5192 - val_mean_absolute_error: 0.3941
    Epoch 18/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.4689 - mean_absolute_error: 0.3890 - val_loss: 0.5126 - val_mean_absolute_error: 0.3914
    Epoch 19/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.4007 - mean_absolute_error: 0.3706 - val_loss: 0.4992 - val_mean_absolute_error: 0.3902
    Epoch 20/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.4377 - mean_absolute_error: 0.3857 - val_loss: 0.4964 - val_mean_absolute_error: 0.3760
    Epoch 21/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.4042 - mean_absolute_error: 0.3472 - val_loss: 0.4749 - val_mean_absolute_error: 0.3768
    Epoch 22/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.3825 - mean_absolute_error: 0.3546 - val_loss: 0.4574 - val_mean_absolute_error: 0.3517
    Epoch 23/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.3678 - mean_absolute_error: 0.3257 - val_loss: 0.4432 - val_mean_absolute_error: 0.3440
    Epoch 24/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.3440 - mean_absolute_error: 0.3146 - val_loss: 0.4216 - val_mean_absolute_error: 0.3364
    Epoch 25/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.3595 - mean_absolute_error: 0.3287 - val_loss: 0.4098 - val_mean_absolute_error: 0.3056
    Epoch 26/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.3446 - mean_absolute_error: 0.2827 - val_loss: 0.3984 - val_mean_absolute_error: 0.2976
    Epoch 27/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.3801 - mean_absolute_error: 0.3110 - val_loss: 0.3787 - val_mean_absolute_error: 0.2883
    Epoch 28/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.2863 - mean_absolute_error: 0.2717 - val_loss: 0.3601 - val_mean_absolute_error: 0.2790
    Epoch 29/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.3381 - mean_absolute_error: 0.2769 - val_loss: 0.3487 - val_mean_absolute_error: 0.2850
    Epoch 30/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - loss: 0.2354 - mean_absolute_error: 0.2561 - val_loss: 0.3353 - val_mean_absolute_error: 0.2940
    Epoch 31/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.3266 - mean_absolute_error: 0.2919 - val_loss: 0.3243 - val_mean_absolute_error: 0.2755
    Epoch 32/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.2489 - mean_absolute_error: 0.2657 - val_loss: 0.3207 - val_mean_absolute_error: 0.2674
    Epoch 33/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.3106 - mean_absolute_error: 0.2760 - val_loss: 0.3066 - val_mean_absolute_error: 0.2616
    Epoch 34/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.2508 - mean_absolute_error: 0.2478 - val_loss: 0.2945 - val_mean_absolute_error: 0.2680
    Epoch 35/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.2616 - mean_absolute_error: 0.2650 - val_loss: 0.2848 - val_mean_absolute_error: 0.2610
    Epoch 36/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.1894 - mean_absolute_error: 0.2335 - val_loss: 0.2837 - val_mean_absolute_error: 0.2791
    Epoch 37/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.2516 - mean_absolute_error: 0.2605 - val_loss: 0.2733 - val_mean_absolute_error: 0.2477
    Epoch 38/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.2085 - mean_absolute_error: 0.2468 - val_loss: 0.2693 - val_mean_absolute_error: 0.2427
    Epoch 39/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1933 - mean_absolute_error: 0.2241 - val_loss: 0.2566 - val_mean_absolute_error: 0.2398
    Epoch 40/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.1517 - mean_absolute_error: 0.2098 - val_loss: 0.2493 - val_mean_absolute_error: 0.2480
    Epoch 41/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.1819 - mean_absolute_error: 0.2314 - val_loss: 0.2477 - val_mean_absolute_error: 0.2319
    Epoch 42/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1681 - mean_absolute_error: 0.2129 - val_loss: 0.2357 - val_mean_absolute_error: 0.2415
    Epoch 43/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1546 - mean_absolute_error: 0.2141 - val_loss: 0.2343 - val_mean_absolute_error: 0.2334
    Epoch 44/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.2173 - mean_absolute_error: 0.2301 - val_loss: 0.2334 - val_mean_absolute_error: 0.2257
    Epoch 45/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1491 - mean_absolute_error: 0.2083 - val_loss: 0.2218 - val_mean_absolute_error: 0.2441
    Epoch 46/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1442 - mean_absolute_error: 0.2099 - val_loss: 0.2160 - val_mean_absolute_error: 0.2196
    Epoch 47/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1461 - mean_absolute_error: 0.2046 - val_loss: 0.2164 - val_mean_absolute_error: 0.2211
    Epoch 48/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.1570 - mean_absolute_error: 0.2119 - val_loss: 0.2067 - val_mean_absolute_error: 0.2139
    Epoch 49/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1181 - mean_absolute_error: 0.1905 - val_loss: 0.2003 - val_mean_absolute_error: 0.2092
    Epoch 50/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1303 - mean_absolute_error: 0.1920 - val_loss: 0.1973 - val_mean_absolute_error: 0.2271
    Epoch 51/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.1392 - mean_absolute_error: 0.2079 - val_loss: 0.1991 - val_mean_absolute_error: 0.1993
    Epoch 52/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1262 - mean_absolute_error: 0.1883 - val_loss: 0.1945 - val_mean_absolute_error: 0.2068
    Epoch 53/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1547 - mean_absolute_error: 0.1959 - val_loss: 0.1878 - val_mean_absolute_error: 0.2088
    Epoch 54/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1603 - mean_absolute_error: 0.2075 - val_loss: 0.1852 - val_mean_absolute_error: 0.1946
    Epoch 55/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1349 - mean_absolute_error: 0.1900 - val_loss: 0.1821 - val_mean_absolute_error: 0.1937
    Epoch 56/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1462 - mean_absolute_error: 0.1931 - val_loss: 0.2041 - val_mean_absolute_error: 0.1937
    Epoch 57/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1488 - mean_absolute_error: 0.1911 - val_loss: 0.1734 - val_mean_absolute_error: 0.1880
    Epoch 58/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1143 - mean_absolute_error: 0.1749 - val_loss: 0.1734 - val_mean_absolute_error: 0.1960
    Epoch 59/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.1157 - mean_absolute_error: 0.1768 - val_loss: 0.1653 - val_mean_absolute_error: 0.1880
    Epoch 60/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1033 - mean_absolute_error: 0.1664 - val_loss: 0.1610 - val_mean_absolute_error: 0.1944
    Epoch 61/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.1327 - mean_absolute_error: 0.1833 - val_loss: 0.1623 - val_mean_absolute_error: 0.1775
    Epoch 62/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1308 - mean_absolute_error: 0.1747 - val_loss: 0.1549 - val_mean_absolute_error: 0.1805
    Epoch 63/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0882 - mean_absolute_error: 0.1549 - val_loss: 0.1478 - val_mean_absolute_error: 0.1856
    Epoch 64/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1232 - mean_absolute_error: 0.1823 - val_loss: 0.1454 - val_mean_absolute_error: 0.1863
    Epoch 65/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1076 - mean_absolute_error: 0.1663 - val_loss: 0.1404 - val_mean_absolute_error: 0.1746
    Epoch 66/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1086 - mean_absolute_error: 0.1707 - val_loss: 0.1382 - val_mean_absolute_error: 0.1728
    Epoch 67/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0879 - mean_absolute_error: 0.1567 - val_loss: 0.1440 - val_mean_absolute_error: 0.1725
    Epoch 68/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1022 - mean_absolute_error: 0.1622 - val_loss: 0.1438 - val_mean_absolute_error: 0.1673
    Epoch 69/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0783 - mean_absolute_error: 0.1513 - val_loss: 0.1327 - val_mean_absolute_error: 0.1646
    Epoch 70/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0812 - mean_absolute_error: 0.1463 - val_loss: 0.1325 - val_mean_absolute_error: 0.1650
    Epoch 71/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0815 - mean_absolute_error: 0.1412 - val_loss: 0.1288 - val_mean_absolute_error: 0.1623
    Epoch 72/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0834 - mean_absolute_error: 0.1423 - val_loss: 0.1319 - val_mean_absolute_error: 0.1640
    Epoch 73/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0724 - mean_absolute_error: 0.1380 - val_loss: 0.1371 - val_mean_absolute_error: 0.1584
    Epoch 74/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.0772 - mean_absolute_error: 0.1403 - val_loss: 0.1231 - val_mean_absolute_error: 0.1595
    Epoch 75/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0615 - mean_absolute_error: 0.1270 - val_loss: 0.1208 - val_mean_absolute_error: 0.1568
    Epoch 76/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0892 - mean_absolute_error: 0.1530 - val_loss: 0.1201 - val_mean_absolute_error: 0.1595
    Epoch 77/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0910 - mean_absolute_error: 0.1476 - val_loss: 0.1141 - val_mean_absolute_error: 0.1490
    Epoch 78/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0655 - mean_absolute_error: 0.1310 - val_loss: 0.1142 - val_mean_absolute_error: 0.1510
    Epoch 79/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0752 - mean_absolute_error: 0.1338 - val_loss: 0.1130 - val_mean_absolute_error: 0.1556
    Epoch 80/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0586 - mean_absolute_error: 0.1278 - val_loss: 0.1104 - val_mean_absolute_error: 0.1483
    Epoch 81/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0612 - mean_absolute_error: 0.1245 - val_loss: 0.1084 - val_mean_absolute_error: 0.1498
    Epoch 82/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0687 - mean_absolute_error: 0.1327 - val_loss: 0.1115 - val_mean_absolute_error: 0.1448
    Epoch 83/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0673 - mean_absolute_error: 0.1234 - val_loss: 0.1190 - val_mean_absolute_error: 0.1415
    Epoch 84/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0783 - mean_absolute_error: 0.1344 - val_loss: 0.1044 - val_mean_absolute_error: 0.1404
    Epoch 85/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0683 - mean_absolute_error: 0.1276 - val_loss: 0.1011 - val_mean_absolute_error: 0.1433
    Epoch 86/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0656 - mean_absolute_error: 0.1293 - val_loss: 0.0991 - val_mean_absolute_error: 0.1499
    Epoch 87/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0522 - mean_absolute_error: 0.1201 - val_loss: 0.0964 - val_mean_absolute_error: 0.1433
    Epoch 88/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0521 - mean_absolute_error: 0.1165 - val_loss: 0.0982 - val_mean_absolute_error: 0.1399
    Epoch 89/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0682 - mean_absolute_error: 0.1274 - val_loss: 0.0955 - val_mean_absolute_error: 0.1407
    Epoch 90/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0573 - mean_absolute_error: 0.1189 - val_loss: 0.0930 - val_mean_absolute_error: 0.1350
    Epoch 91/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0565 - mean_absolute_error: 0.1178 - val_loss: 0.0987 - val_mean_absolute_error: 0.1317
    Epoch 92/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0710 - mean_absolute_error: 0.1251 - val_loss: 0.0977 - val_mean_absolute_error: 0.1374
    Epoch 93/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0622 - mean_absolute_error: 0.1182 - val_loss: 0.0906 - val_mean_absolute_error: 0.1348
    Epoch 94/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0634 - mean_absolute_error: 0.1192 - val_loss: 0.0936 - val_mean_absolute_error: 0.1321
    Epoch 95/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0527 - mean_absolute_error: 0.1123 - val_loss: 0.0961 - val_mean_absolute_error: 0.1331
    Epoch 96/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0507 - mean_absolute_error: 0.1073 - val_loss: 0.0846 - val_mean_absolute_error: 0.1363
    Epoch 97/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0524 - mean_absolute_error: 0.1196 - val_loss: 0.0901 - val_mean_absolute_error: 0.1370
    Epoch 98/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0521 - mean_absolute_error: 0.1139 - val_loss: 0.0913 - val_mean_absolute_error: 0.1306
    Epoch 99/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0433 - mean_absolute_error: 0.1041 - val_loss: 0.0870 - val_mean_absolute_error: 0.1291
    Epoch 100/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0454 - mean_absolute_error: 0.1060 - val_loss: 0.0841 - val_mean_absolute_error: 0.1337
    Epoch 101/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - loss: 0.0434 - mean_absolute_error: 0.1062 - val_loss: 0.0825 - val_mean_absolute_error: 0.1272
    Epoch 102/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0441 - mean_absolute_error: 0.1075 - val_loss: 0.0828 - val_mean_absolute_error: 0.1294
    Epoch 103/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0489 - mean_absolute_error: 0.1099 - val_loss: 0.0834 - val_mean_absolute_error: 0.1341
    Epoch 104/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0450 - mean_absolute_error: 0.1068 - val_loss: 0.0793 - val_mean_absolute_error: 0.1233
    Epoch 105/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0524 - mean_absolute_error: 0.1140 - val_loss: 0.0795 - val_mean_absolute_error: 0.1226
    Epoch 106/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0372 - mean_absolute_error: 0.0995 - val_loss: 0.0778 - val_mean_absolute_error: 0.1253
    Epoch 107/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0623 - mean_absolute_error: 0.1164 - val_loss: 0.0759 - val_mean_absolute_error: 0.1209
    Epoch 108/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - loss: 0.0394 - mean_absolute_error: 0.1000 - val_loss: 0.0805 - val_mean_absolute_error: 0.1220
    Epoch 109/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0399 - mean_absolute_error: 0.0988 - val_loss: 0.0720 - val_mean_absolute_error: 0.1208
    Epoch 110/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0506 - mean_absolute_error: 0.1044 - val_loss: 0.0915 - val_mean_absolute_error: 0.1242
    Epoch 111/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0689 - mean_absolute_error: 0.1135 - val_loss: 0.0765 - val_mean_absolute_error: 0.1170
    Epoch 112/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0402 - mean_absolute_error: 0.0973 - val_loss: 0.0767 - val_mean_absolute_error: 0.1168
    Epoch 113/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0416 - mean_absolute_error: 0.1008 - val_loss: 0.0723 - val_mean_absolute_error: 0.1260
    Epoch 114/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0366 - mean_absolute_error: 0.1005 - val_loss: 0.0708 - val_mean_absolute_error: 0.1220
    Epoch 115/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.0498 - mean_absolute_error: 0.1090 - val_loss: 0.0745 - val_mean_absolute_error: 0.1182
    Epoch 116/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0446 - mean_absolute_error: 0.0991 - val_loss: 0.0705 - val_mean_absolute_error: 0.1127
    Epoch 117/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0442 - mean_absolute_error: 0.0992 - val_loss: 0.0689 - val_mean_absolute_error: 0.1187
    Epoch 118/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0331 - mean_absolute_error: 0.0950 - val_loss: 0.0732 - val_mean_absolute_error: 0.1183
    Epoch 119/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0361 - mean_absolute_error: 0.0945 - val_loss: 0.0677 - val_mean_absolute_error: 0.1201
    Epoch 120/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0397 - mean_absolute_error: 0.1027 - val_loss: 0.0669 - val_mean_absolute_error: 0.1190
    Epoch 121/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0342 - mean_absolute_error: 0.1010 - val_loss: 0.0709 - val_mean_absolute_error: 0.1189
    Epoch 122/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0424 - mean_absolute_error: 0.0963 - val_loss: 0.0652 - val_mean_absolute_error: 0.1113
    Epoch 123/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0391 - mean_absolute_error: 0.0933 - val_loss: 0.0630 - val_mean_absolute_error: 0.1161
    Epoch 124/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0284 - mean_absolute_error: 0.0879 - val_loss: 0.0835 - val_mean_absolute_error: 0.1216
    Epoch 125/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0439 - mean_absolute_error: 0.1075 - val_loss: 0.0679 - val_mean_absolute_error: 0.1146
    Epoch 126/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0452 - mean_absolute_error: 0.1049 - val_loss: 0.0650 - val_mean_absolute_error: 0.1134
    Epoch 127/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0328 - mean_absolute_error: 0.0914 - val_loss: 0.0644 - val_mean_absolute_error: 0.1094
    Epoch 128/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0338 - mean_absolute_error: 0.0902 - val_loss: 0.0609 - val_mean_absolute_error: 0.1095
    Epoch 129/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0306 - mean_absolute_error: 0.0862 - val_loss: 0.0591 - val_mean_absolute_error: 0.1088
    Epoch 130/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0318 - mean_absolute_error: 0.0881 - val_loss: 0.0633 - val_mean_absolute_error: 0.1118
    Epoch 131/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0295 - mean_absolute_error: 0.0861 - val_loss: 0.0611 - val_mean_absolute_error: 0.1109
    Epoch 132/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0308 - mean_absolute_error: 0.0889 - val_loss: 0.0614 - val_mean_absolute_error: 0.1087
    Epoch 133/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0356 - mean_absolute_error: 0.0900 - val_loss: 0.0592 - val_mean_absolute_error: 0.1053
    Epoch 134/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0316 - mean_absolute_error: 0.0910 - val_loss: 0.0626 - val_mean_absolute_error: 0.1173
    Epoch 135/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0346 - mean_absolute_error: 0.0909 - val_loss: 0.0631 - val_mean_absolute_error: 0.1131
    Epoch 136/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0378 - mean_absolute_error: 0.0930 - val_loss: 0.0582 - val_mean_absolute_error: 0.1072
    Epoch 137/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0317 - mean_absolute_error: 0.0874 - val_loss: 0.0597 - val_mean_absolute_error: 0.1098
    Epoch 138/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0363 - mean_absolute_error: 0.0917 - val_loss: 0.0657 - val_mean_absolute_error: 0.1112
    Epoch 139/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0325 - mean_absolute_error: 0.0888 - val_loss: 0.0604 - val_mean_absolute_error: 0.1130
    Epoch 140/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0327 - mean_absolute_error: 0.0876 - val_loss: 0.0575 - val_mean_absolute_error: 0.1078
    Epoch 141/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0400 - mean_absolute_error: 0.0993 - val_loss: 0.0538 - val_mean_absolute_error: 0.1011
    Epoch 142/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0364 - mean_absolute_error: 0.0912 - val_loss: 0.0529 - val_mean_absolute_error: 0.1020
    Epoch 143/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0278 - mean_absolute_error: 0.0840 - val_loss: 0.0557 - val_mean_absolute_error: 0.1044
    Epoch 144/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0362 - mean_absolute_error: 0.0833 - val_loss: 0.0580 - val_mean_absolute_error: 0.1056
    Epoch 145/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0229 - mean_absolute_error: 0.0787 - val_loss: 0.0518 - val_mean_absolute_error: 0.1029
    Epoch 146/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0309 - mean_absolute_error: 0.0875 - val_loss: 0.0575 - val_mean_absolute_error: 0.1067
    Epoch 147/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0299 - mean_absolute_error: 0.0854 - val_loss: 0.0532 - val_mean_absolute_error: 0.1032
    Epoch 148/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0272 - mean_absolute_error: 0.0802 - val_loss: 0.0546 - val_mean_absolute_error: 0.1013
    Epoch 149/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0245 - mean_absolute_error: 0.0798 - val_loss: 0.0611 - val_mean_absolute_error: 0.1051
    Epoch 150/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0349 - mean_absolute_error: 0.0848 - val_loss: 0.0565 - val_mean_absolute_error: 0.1023
    Epoch 151/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0382 - mean_absolute_error: 0.0856 - val_loss: 0.0557 - val_mean_absolute_error: 0.1019
    Epoch 152/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0173 - mean_absolute_error: 0.0717 - val_loss: 0.0570 - val_mean_absolute_error: 0.1077
    Epoch 153/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0365 - mean_absolute_error: 0.0858 - val_loss: 0.0536 - val_mean_absolute_error: 0.1053
    Epoch 154/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0306 - mean_absolute_error: 0.0833 - val_loss: 0.0530 - val_mean_absolute_error: 0.0997
    Epoch 155/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0274 - mean_absolute_error: 0.0796 - val_loss: 0.0504 - val_mean_absolute_error: 0.0971
    Epoch 156/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0240 - mean_absolute_error: 0.0779 - val_loss: 0.0567 - val_mean_absolute_error: 0.0980
    Epoch 157/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0229 - mean_absolute_error: 0.0777 - val_loss: 0.0485 - val_mean_absolute_error: 0.0957
    Epoch 158/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0280 - mean_absolute_error: 0.0808 - val_loss: 0.0646 - val_mean_absolute_error: 0.1036
    Epoch 159/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0334 - mean_absolute_error: 0.0804 - val_loss: 0.0485 - val_mean_absolute_error: 0.0968
    Epoch 160/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0272 - mean_absolute_error: 0.0772 - val_loss: 0.0486 - val_mean_absolute_error: 0.0985
    Epoch 161/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0173 - mean_absolute_error: 0.0715 - val_loss: 0.0474 - val_mean_absolute_error: 0.1014
    Epoch 162/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0303 - mean_absolute_error: 0.0865 - val_loss: 0.0541 - val_mean_absolute_error: 0.0971
    Epoch 163/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0239 - mean_absolute_error: 0.0771 - val_loss: 0.0461 - val_mean_absolute_error: 0.0951
    Epoch 164/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0229 - mean_absolute_error: 0.0735 - val_loss: 0.0537 - val_mean_absolute_error: 0.1012
    Epoch 165/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0254 - mean_absolute_error: 0.0797 - val_loss: 0.0470 - val_mean_absolute_error: 0.0958
    Epoch 166/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0219 - mean_absolute_error: 0.0758 - val_loss: 0.0471 - val_mean_absolute_error: 0.0942
    Epoch 167/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0206 - mean_absolute_error: 0.0691 - val_loss: 0.0461 - val_mean_absolute_error: 0.0956
    Epoch 168/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0302 - mean_absolute_error: 0.0790 - val_loss: 0.0503 - val_mean_absolute_error: 0.0964
    Epoch 169/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0226 - mean_absolute_error: 0.0707 - val_loss: 0.0424 - val_mean_absolute_error: 0.0923
    Epoch 170/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0285 - mean_absolute_error: 0.0832 - val_loss: 0.0499 - val_mean_absolute_error: 0.0940
    Epoch 171/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0291 - mean_absolute_error: 0.0786 - val_loss: 0.0516 - val_mean_absolute_error: 0.0928
    Epoch 172/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0316 - mean_absolute_error: 0.0778 - val_loss: 0.0458 - val_mean_absolute_error: 0.0924
    Epoch 173/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0224 - mean_absolute_error: 0.0739 - val_loss: 0.0501 - val_mean_absolute_error: 0.0921
    Epoch 174/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0167 - mean_absolute_error: 0.0665 - val_loss: 0.0440 - val_mean_absolute_error: 0.0906
    Epoch 175/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0180 - mean_absolute_error: 0.0657 - val_loss: 0.0487 - val_mean_absolute_error: 0.1000
    Epoch 176/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0234 - mean_absolute_error: 0.0748 - val_loss: 0.0446 - val_mean_absolute_error: 0.1055
    Epoch 177/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0203 - mean_absolute_error: 0.0742 - val_loss: 0.0561 - val_mean_absolute_error: 0.0968
    Epoch 178/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0403 - mean_absolute_error: 0.0897 - val_loss: 0.0406 - val_mean_absolute_error: 0.0927
    Epoch 179/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0279 - mean_absolute_error: 0.0785 - val_loss: 0.0413 - val_mean_absolute_error: 0.0937
    Epoch 180/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0185 - mean_absolute_error: 0.0690 - val_loss: 0.0494 - val_mean_absolute_error: 0.0942
    Epoch 181/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0171 - mean_absolute_error: 0.0679 - val_loss: 0.0434 - val_mean_absolute_error: 0.0909
    Epoch 182/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0216 - mean_absolute_error: 0.0718 - val_loss: 0.0432 - val_mean_absolute_error: 0.0922
    Epoch 183/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0228 - mean_absolute_error: 0.0704 - val_loss: 0.0525 - val_mean_absolute_error: 0.1058
    Epoch 184/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0290 - mean_absolute_error: 0.0799 - val_loss: 0.0471 - val_mean_absolute_error: 0.0939
    Epoch 185/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0241 - mean_absolute_error: 0.0714 - val_loss: 0.0467 - val_mean_absolute_error: 0.0919
    Epoch 186/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0219 - mean_absolute_error: 0.0719 - val_loss: 0.0428 - val_mean_absolute_error: 0.0834
    Epoch 187/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0246 - mean_absolute_error: 0.0685 - val_loss: 0.0377 - val_mean_absolute_error: 0.0840
    Epoch 188/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0206 - mean_absolute_error: 0.0665 - val_loss: 0.0526 - val_mean_absolute_error: 0.0869
    Epoch 189/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0178 - mean_absolute_error: 0.0671 - val_loss: 0.0460 - val_mean_absolute_error: 0.0892
    Epoch 190/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0216 - mean_absolute_error: 0.0691 - val_loss: 0.0389 - val_mean_absolute_error: 0.0855
    Epoch 191/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0153 - mean_absolute_error: 0.0616 - val_loss: 0.0429 - val_mean_absolute_error: 0.0905
    Epoch 192/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0215 - mean_absolute_error: 0.0671 - val_loss: 0.0412 - val_mean_absolute_error: 0.0840
    Epoch 193/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0132 - mean_absolute_error: 0.0594 - val_loss: 0.0382 - val_mean_absolute_error: 0.0833
    Epoch 194/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0170 - mean_absolute_error: 0.0656 - val_loss: 0.0408 - val_mean_absolute_error: 0.0821
    Epoch 195/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0166 - mean_absolute_error: 0.0625 - val_loss: 0.0391 - val_mean_absolute_error: 0.0950
    Epoch 196/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0216 - mean_absolute_error: 0.0748 - val_loss: 0.0411 - val_mean_absolute_error: 0.0897
    Epoch 197/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0115 - mean_absolute_error: 0.0629 - val_loss: 0.0387 - val_mean_absolute_error: 0.0912
    Epoch 198/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0166 - mean_absolute_error: 0.0650 - val_loss: 0.0386 - val_mean_absolute_error: 0.0862
    Epoch 199/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0168 - mean_absolute_error: 0.0633 - val_loss: 0.0412 - val_mean_absolute_error: 0.0958
    Epoch 200/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0154 - mean_absolute_error: 0.0644 - val_loss: 0.0362 - val_mean_absolute_error: 0.0800
    Epoch 201/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0194 - mean_absolute_error: 0.0621 - val_loss: 0.0396 - val_mean_absolute_error: 0.0823
    Epoch 202/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0188 - mean_absolute_error: 0.0687 - val_loss: 0.0441 - val_mean_absolute_error: 0.0942
    Epoch 203/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0205 - mean_absolute_error: 0.0695 - val_loss: 0.0386 - val_mean_absolute_error: 0.0882
    Epoch 204/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0143 - mean_absolute_error: 0.0629 - val_loss: 0.0360 - val_mean_absolute_error: 0.0806
    Epoch 205/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0166 - mean_absolute_error: 0.0632 - val_loss: 0.0362 - val_mean_absolute_error: 0.0792
    Epoch 206/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0203 - mean_absolute_error: 0.0645 - val_loss: 0.0420 - val_mean_absolute_error: 0.0824
    Epoch 207/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0170 - mean_absolute_error: 0.0651 - val_loss: 0.0375 - val_mean_absolute_error: 0.0886
    Epoch 208/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0162 - mean_absolute_error: 0.0631 - val_loss: 0.0443 - val_mean_absolute_error: 0.0903
    Epoch 209/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0171 - mean_absolute_error: 0.0692 - val_loss: 0.0384 - val_mean_absolute_error: 0.0801
    Epoch 210/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0152 - mean_absolute_error: 0.0647 - val_loss: 0.0409 - val_mean_absolute_error: 0.0882
    Epoch 211/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0230 - mean_absolute_error: 0.0626 - val_loss: 0.0353 - val_mean_absolute_error: 0.0871
    Epoch 212/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0230 - mean_absolute_error: 0.0706 - val_loss: 0.0383 - val_mean_absolute_error: 0.0842
    Epoch 213/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0164 - mean_absolute_error: 0.0588 - val_loss: 0.0393 - val_mean_absolute_error: 0.0889
    Epoch 214/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0193 - mean_absolute_error: 0.0680 - val_loss: 0.0334 - val_mean_absolute_error: 0.0774
    Epoch 215/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0162 - mean_absolute_error: 0.0591 - val_loss: 0.0315 - val_mean_absolute_error: 0.0796
    Epoch 216/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0133 - mean_absolute_error: 0.0603 - val_loss: 0.0351 - val_mean_absolute_error: 0.0821
    Epoch 217/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0194 - mean_absolute_error: 0.0663 - val_loss: 0.0354 - val_mean_absolute_error: 0.0772
    Epoch 218/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0159 - mean_absolute_error: 0.0598 - val_loss: 0.0330 - val_mean_absolute_error: 0.0790
    Epoch 219/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0118 - mean_absolute_error: 0.0580 - val_loss: 0.0377 - val_mean_absolute_error: 0.0813
    Epoch 220/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0208 - mean_absolute_error: 0.0673 - val_loss: 0.0340 - val_mean_absolute_error: 0.0818
    Epoch 221/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0131 - mean_absolute_error: 0.0588 - val_loss: 0.0327 - val_mean_absolute_error: 0.0797
    Epoch 222/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0135 - mean_absolute_error: 0.0604 - val_loss: 0.0386 - val_mean_absolute_error: 0.0842
    Epoch 223/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0186 - mean_absolute_error: 0.0667 - val_loss: 0.0375 - val_mean_absolute_error: 0.0809
    Epoch 224/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0138 - mean_absolute_error: 0.0544 - val_loss: 0.0339 - val_mean_absolute_error: 0.0786
    Epoch 225/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0143 - mean_absolute_error: 0.0584 - val_loss: 0.0314 - val_mean_absolute_error: 0.0784
    Epoch 226/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0138 - mean_absolute_error: 0.0574 - val_loss: 0.0319 - val_mean_absolute_error: 0.0788
    Epoch 227/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0171 - mean_absolute_error: 0.0597 - val_loss: 0.0329 - val_mean_absolute_error: 0.0737
    Epoch 228/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0151 - mean_absolute_error: 0.0546 - val_loss: 0.0305 - val_mean_absolute_error: 0.0766
    Epoch 229/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0138 - mean_absolute_error: 0.0602 - val_loss: 0.0385 - val_mean_absolute_error: 0.0821
    Epoch 230/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0131 - mean_absolute_error: 0.0603 - val_loss: 0.0324 - val_mean_absolute_error: 0.0782
    Epoch 231/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0127 - mean_absolute_error: 0.0558 - val_loss: 0.0313 - val_mean_absolute_error: 0.0729
    Epoch 232/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0139 - mean_absolute_error: 0.0539 - val_loss: 0.0327 - val_mean_absolute_error: 0.0748
    Epoch 233/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0133 - mean_absolute_error: 0.0578 - val_loss: 0.0366 - val_mean_absolute_error: 0.0809
    Epoch 234/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0114 - mean_absolute_error: 0.0560 - val_loss: 0.0401 - val_mean_absolute_error: 0.0871
    Epoch 235/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0204 - mean_absolute_error: 0.0631 - val_loss: 0.0323 - val_mean_absolute_error: 0.0851
    Epoch 236/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0221 - mean_absolute_error: 0.0628 - val_loss: 0.0296 - val_mean_absolute_error: 0.0728
    Epoch 237/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0151 - mean_absolute_error: 0.0606 - val_loss: 0.0301 - val_mean_absolute_error: 0.0736
    Epoch 238/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0166 - mean_absolute_error: 0.0587 - val_loss: 0.0350 - val_mean_absolute_error: 0.0766
    Epoch 239/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0112 - mean_absolute_error: 0.0551 - val_loss: 0.0293 - val_mean_absolute_error: 0.0742
    Epoch 240/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0131 - mean_absolute_error: 0.0567 - val_loss: 0.0290 - val_mean_absolute_error: 0.0720
    Epoch 241/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0151 - mean_absolute_error: 0.0588 - val_loss: 0.0308 - val_mean_absolute_error: 0.0751
    Epoch 242/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0135 - mean_absolute_error: 0.0554 - val_loss: 0.0332 - val_mean_absolute_error: 0.0764
    Epoch 243/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0162 - mean_absolute_error: 0.0579 - val_loss: 0.0308 - val_mean_absolute_error: 0.0764
    Epoch 244/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0121 - mean_absolute_error: 0.0541 - val_loss: 0.0312 - val_mean_absolute_error: 0.0746
    Epoch 245/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0112 - mean_absolute_error: 0.0520 - val_loss: 0.0309 - val_mean_absolute_error: 0.0725
    Epoch 246/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0113 - mean_absolute_error: 0.0498 - val_loss: 0.0277 - val_mean_absolute_error: 0.0677
    Epoch 247/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0101 - mean_absolute_error: 0.0540 - val_loss: 0.0386 - val_mean_absolute_error: 0.0924
    Epoch 248/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0225 - mean_absolute_error: 0.0681 - val_loss: 0.0289 - val_mean_absolute_error: 0.0757
    Epoch 249/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0232 - mean_absolute_error: 0.0639 - val_loss: 0.0285 - val_mean_absolute_error: 0.0715
    Epoch 250/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0136 - mean_absolute_error: 0.0559 - val_loss: 0.0263 - val_mean_absolute_error: 0.0685
    Epoch 251/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0124 - mean_absolute_error: 0.0522 - val_loss: 0.0346 - val_mean_absolute_error: 0.0771
    Epoch 252/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - loss: 0.0115 - mean_absolute_error: 0.0540 - val_loss: 0.0337 - val_mean_absolute_error: 0.0779
    Epoch 253/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0104 - mean_absolute_error: 0.0514 - val_loss: 0.0265 - val_mean_absolute_error: 0.0715
    Epoch 254/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0170 - mean_absolute_error: 0.0612 - val_loss: 0.0352 - val_mean_absolute_error: 0.0723
    Epoch 255/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0128 - mean_absolute_error: 0.0609 - val_loss: 0.0332 - val_mean_absolute_error: 0.0692
    Epoch 256/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0147 - mean_absolute_error: 0.0556 - val_loss: 0.0287 - val_mean_absolute_error: 0.0684
    Epoch 257/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0105 - mean_absolute_error: 0.0524 - val_loss: 0.0380 - val_mean_absolute_error: 0.0759
    Epoch 258/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0154 - mean_absolute_error: 0.0593 - val_loss: 0.0251 - val_mean_absolute_error: 0.0674
    Epoch 259/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0095 - mean_absolute_error: 0.0491 - val_loss: 0.0264 - val_mean_absolute_error: 0.0676
    Epoch 260/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0112 - mean_absolute_error: 0.0516 - val_loss: 0.0302 - val_mean_absolute_error: 0.0844
    Epoch 261/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0098 - mean_absolute_error: 0.0535 - val_loss: 0.0267 - val_mean_absolute_error: 0.0760
    Epoch 262/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0127 - mean_absolute_error: 0.0555 - val_loss: 0.0246 - val_mean_absolute_error: 0.0724
    Epoch 263/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0110 - mean_absolute_error: 0.0518 - val_loss: 0.0275 - val_mean_absolute_error: 0.0687
    Epoch 264/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0102 - mean_absolute_error: 0.0502 - val_loss: 0.0246 - val_mean_absolute_error: 0.0696
    Epoch 265/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0112 - mean_absolute_error: 0.0518 - val_loss: 0.0347 - val_mean_absolute_error: 0.0705
    Epoch 266/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0111 - mean_absolute_error: 0.0518 - val_loss: 0.0294 - val_mean_absolute_error: 0.0662
    Epoch 267/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0106 - mean_absolute_error: 0.0505 - val_loss: 0.0268 - val_mean_absolute_error: 0.0670
    Epoch 268/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0096 - mean_absolute_error: 0.0492 - val_loss: 0.0246 - val_mean_absolute_error: 0.0645
    Epoch 269/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0115 - mean_absolute_error: 0.0490 - val_loss: 0.0328 - val_mean_absolute_error: 0.0743
    Epoch 270/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0178 - mean_absolute_error: 0.0613 - val_loss: 0.0256 - val_mean_absolute_error: 0.0737
    Epoch 271/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0127 - mean_absolute_error: 0.0574 - val_loss: 0.0218 - val_mean_absolute_error: 0.0644
    Epoch 272/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0120 - mean_absolute_error: 0.0533 - val_loss: 0.0503 - val_mean_absolute_error: 0.0775
    Epoch 273/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0138 - mean_absolute_error: 0.0602 - val_loss: 0.0330 - val_mean_absolute_error: 0.0718
    Epoch 274/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0191 - mean_absolute_error: 0.0602 - val_loss: 0.0228 - val_mean_absolute_error: 0.0646
    Epoch 275/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0109 - mean_absolute_error: 0.0531 - val_loss: 0.0282 - val_mean_absolute_error: 0.0709
    Epoch 276/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0089 - mean_absolute_error: 0.0487 - val_loss: 0.0210 - val_mean_absolute_error: 0.0623
    Epoch 277/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0087 - mean_absolute_error: 0.0466 - val_loss: 0.0289 - val_mean_absolute_error: 0.0664
    Epoch 278/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0143 - mean_absolute_error: 0.0520 - val_loss: 0.0253 - val_mean_absolute_error: 0.0637
    Epoch 279/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0130 - mean_absolute_error: 0.0492 - val_loss: 0.0318 - val_mean_absolute_error: 0.0759
    Epoch 280/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0126 - mean_absolute_error: 0.0545 - val_loss: 0.0249 - val_mean_absolute_error: 0.0669
    Epoch 281/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0094 - mean_absolute_error: 0.0487 - val_loss: 0.0273 - val_mean_absolute_error: 0.0639
    Epoch 282/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0122 - mean_absolute_error: 0.0492 - val_loss: 0.0238 - val_mean_absolute_error: 0.0753
    Epoch 283/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0110 - mean_absolute_error: 0.0547 - val_loss: 0.0255 - val_mean_absolute_error: 0.0651
    Epoch 284/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0116 - mean_absolute_error: 0.0516 - val_loss: 0.0218 - val_mean_absolute_error: 0.0608
    Epoch 285/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0090 - mean_absolute_error: 0.0436 - val_loss: 0.0235 - val_mean_absolute_error: 0.0605
    Epoch 286/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0121 - mean_absolute_error: 0.0498 - val_loss: 0.0248 - val_mean_absolute_error: 0.0764
    Epoch 287/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0068 - mean_absolute_error: 0.0476 - val_loss: 0.0275 - val_mean_absolute_error: 0.0683
    Epoch 288/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0117 - mean_absolute_error: 0.0502 - val_loss: 0.0270 - val_mean_absolute_error: 0.0647
    Epoch 289/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0099 - mean_absolute_error: 0.0496 - val_loss: 0.0258 - val_mean_absolute_error: 0.0615
    Epoch 290/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0102 - mean_absolute_error: 0.0504 - val_loss: 0.0228 - val_mean_absolute_error: 0.0599
    Epoch 291/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0076 - mean_absolute_error: 0.0474 - val_loss: 0.0220 - val_mean_absolute_error: 0.0603
    Epoch 292/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0081 - mean_absolute_error: 0.0472 - val_loss: 0.0303 - val_mean_absolute_error: 0.0635
    Epoch 293/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0158 - mean_absolute_error: 0.0550 - val_loss: 0.0208 - val_mean_absolute_error: 0.0643
    Epoch 294/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0119 - mean_absolute_error: 0.0535 - val_loss: 0.0315 - val_mean_absolute_error: 0.0699
    Epoch 295/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0166 - mean_absolute_error: 0.0560 - val_loss: 0.0228 - val_mean_absolute_error: 0.0612
    Epoch 296/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0084 - mean_absolute_error: 0.0426 - val_loss: 0.0247 - val_mean_absolute_error: 0.0596
    Epoch 297/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0076 - mean_absolute_error: 0.0450 - val_loss: 0.0236 - val_mean_absolute_error: 0.0631
    Epoch 298/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0108 - mean_absolute_error: 0.0482 - val_loss: 0.0230 - val_mean_absolute_error: 0.0616
    Epoch 299/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0107 - mean_absolute_error: 0.0485 - val_loss: 0.0230 - val_mean_absolute_error: 0.0636
    Epoch 300/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0131 - mean_absolute_error: 0.0484 - val_loss: 0.0218 - val_mean_absolute_error: 0.0581
    Epoch 301/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0097 - mean_absolute_error: 0.0480 - val_loss: 0.0199 - val_mean_absolute_error: 0.0611
    Epoch 302/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0117 - mean_absolute_error: 0.0527 - val_loss: 0.0210 - val_mean_absolute_error: 0.0602
    Epoch 303/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0105 - mean_absolute_error: 0.0491 - val_loss: 0.0210 - val_mean_absolute_error: 0.0598
    Epoch 304/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0116 - mean_absolute_error: 0.0472 - val_loss: 0.0223 - val_mean_absolute_error: 0.0590
    Epoch 305/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0087 - mean_absolute_error: 0.0439 - val_loss: 0.0225 - val_mean_absolute_error: 0.0646
    Epoch 306/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0106 - mean_absolute_error: 0.0521 - val_loss: 0.0225 - val_mean_absolute_error: 0.0709
    Epoch 307/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0104 - mean_absolute_error: 0.0550 - val_loss: 0.0275 - val_mean_absolute_error: 0.0751
    Epoch 308/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0166 - mean_absolute_error: 0.0574 - val_loss: 0.0224 - val_mean_absolute_error: 0.0604
    Epoch 309/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0080 - mean_absolute_error: 0.0450 - val_loss: 0.0240 - val_mean_absolute_error: 0.0602
    Epoch 310/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0076 - mean_absolute_error: 0.0435 - val_loss: 0.0317 - val_mean_absolute_error: 0.0644
    Epoch 311/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0099 - mean_absolute_error: 0.0509 - val_loss: 0.0232 - val_mean_absolute_error: 0.0588
    Epoch 312/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0119 - mean_absolute_error: 0.0487 - val_loss: 0.0204 - val_mean_absolute_error: 0.0587
    Epoch 313/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0139 - mean_absolute_error: 0.0491 - val_loss: 0.0177 - val_mean_absolute_error: 0.0596
    Epoch 314/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0097 - mean_absolute_error: 0.0481 - val_loss: 0.0188 - val_mean_absolute_error: 0.0602
    Epoch 315/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0119 - mean_absolute_error: 0.0500 - val_loss: 0.0208 - val_mean_absolute_error: 0.0603
    Epoch 316/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0079 - mean_absolute_error: 0.0434 - val_loss: 0.0223 - val_mean_absolute_error: 0.0591
    Epoch 317/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0079 - mean_absolute_error: 0.0444 - val_loss: 0.0197 - val_mean_absolute_error: 0.0567
    Epoch 318/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0115 - mean_absolute_error: 0.0466 - val_loss: 0.0194 - val_mean_absolute_error: 0.0562
    Epoch 319/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0116 - mean_absolute_error: 0.0506 - val_loss: 0.0216 - val_mean_absolute_error: 0.0678
    Epoch 320/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0127 - mean_absolute_error: 0.0544 - val_loss: 0.0294 - val_mean_absolute_error: 0.0598
    Epoch 321/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0082 - mean_absolute_error: 0.0433 - val_loss: 0.0188 - val_mean_absolute_error: 0.0570
    Epoch 322/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0089 - mean_absolute_error: 0.0455 - val_loss: 0.0202 - val_mean_absolute_error: 0.0546
    Epoch 323/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0105 - mean_absolute_error: 0.0449 - val_loss: 0.0202 - val_mean_absolute_error: 0.0610
    Epoch 324/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0078 - mean_absolute_error: 0.0439 - val_loss: 0.0201 - val_mean_absolute_error: 0.0536
    Epoch 325/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0083 - mean_absolute_error: 0.0462 - val_loss: 0.0215 - val_mean_absolute_error: 0.0560
    Epoch 326/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0062 - mean_absolute_error: 0.0421 - val_loss: 0.0246 - val_mean_absolute_error: 0.0611
    Epoch 327/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0117 - mean_absolute_error: 0.0522 - val_loss: 0.0190 - val_mean_absolute_error: 0.0707
    Epoch 328/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0084 - mean_absolute_error: 0.0489 - val_loss: 0.0197 - val_mean_absolute_error: 0.0544
    Epoch 329/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0082 - mean_absolute_error: 0.0452 - val_loss: 0.0171 - val_mean_absolute_error: 0.0573
    Epoch 330/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0072 - mean_absolute_error: 0.0419 - val_loss: 0.0195 - val_mean_absolute_error: 0.0530
    Epoch 331/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0083 - mean_absolute_error: 0.0467 - val_loss: 0.0288 - val_mean_absolute_error: 0.0660
    Epoch 332/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0124 - mean_absolute_error: 0.0550 - val_loss: 0.0186 - val_mean_absolute_error: 0.0601
    Epoch 333/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0110 - mean_absolute_error: 0.0497 - val_loss: 0.0247 - val_mean_absolute_error: 0.0618
    Epoch 334/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0065 - mean_absolute_error: 0.0423 - val_loss: 0.0216 - val_mean_absolute_error: 0.0569
    Epoch 335/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0059 - mean_absolute_error: 0.0410 - val_loss: 0.0238 - val_mean_absolute_error: 0.0593
    Epoch 336/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0101 - mean_absolute_error: 0.0483 - val_loss: 0.0202 - val_mean_absolute_error: 0.0542
    Epoch 337/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0060 - mean_absolute_error: 0.0380 - val_loss: 0.0201 - val_mean_absolute_error: 0.0670
    Epoch 338/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0107 - mean_absolute_error: 0.0507 - val_loss: 0.0205 - val_mean_absolute_error: 0.0564
    Epoch 339/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0072 - mean_absolute_error: 0.0443 - val_loss: 0.0195 - val_mean_absolute_error: 0.0551
    Epoch 340/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0069 - mean_absolute_error: 0.0417 - val_loss: 0.0198 - val_mean_absolute_error: 0.0566
    Epoch 341/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0078 - mean_absolute_error: 0.0410 - val_loss: 0.0177 - val_mean_absolute_error: 0.0546
    Epoch 342/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0165 - mean_absolute_error: 0.0539 - val_loss: 0.0238 - val_mean_absolute_error: 0.0560
    Epoch 343/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0090 - mean_absolute_error: 0.0463 - val_loss: 0.0185 - val_mean_absolute_error: 0.0514
    Epoch 344/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0056 - mean_absolute_error: 0.0394 - val_loss: 0.0187 - val_mean_absolute_error: 0.0581
    Epoch 345/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0103 - mean_absolute_error: 0.0465 - val_loss: 0.0188 - val_mean_absolute_error: 0.0582
    Epoch 346/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0102 - mean_absolute_error: 0.0472 - val_loss: 0.0183 - val_mean_absolute_error: 0.0583
    Epoch 347/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0102 - mean_absolute_error: 0.0459 - val_loss: 0.0201 - val_mean_absolute_error: 0.0528
    Epoch 348/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0081 - mean_absolute_error: 0.0430 - val_loss: 0.0178 - val_mean_absolute_error: 0.0532
    Epoch 349/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0056 - mean_absolute_error: 0.0392 - val_loss: 0.0163 - val_mean_absolute_error: 0.0530
    Epoch 350/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0056 - mean_absolute_error: 0.0374 - val_loss: 0.0171 - val_mean_absolute_error: 0.0508
    Epoch 351/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0046 - mean_absolute_error: 0.0364 - val_loss: 0.0234 - val_mean_absolute_error: 0.0618
    Epoch 352/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0084 - mean_absolute_error: 0.0449 - val_loss: 0.0196 - val_mean_absolute_error: 0.0615
    Epoch 353/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0093 - mean_absolute_error: 0.0477 - val_loss: 0.0211 - val_mean_absolute_error: 0.0541
    Epoch 354/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0124 - mean_absolute_error: 0.0467 - val_loss: 0.0426 - val_mean_absolute_error: 0.0844
    Epoch 355/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0244 - mean_absolute_error: 0.0636 - val_loss: 0.0243 - val_mean_absolute_error: 0.0614
    Epoch 356/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0093 - mean_absolute_error: 0.0470 - val_loss: 0.0159 - val_mean_absolute_error: 0.0532
    Epoch 357/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0074 - mean_absolute_error: 0.0433 - val_loss: 0.0198 - val_mean_absolute_error: 0.0567
    Epoch 358/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0078 - mean_absolute_error: 0.0435 - val_loss: 0.0163 - val_mean_absolute_error: 0.0546
    Epoch 359/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0067 - mean_absolute_error: 0.0409 - val_loss: 0.0218 - val_mean_absolute_error: 0.0520
    Epoch 360/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0050 - mean_absolute_error: 0.0382 - val_loss: 0.0190 - val_mean_absolute_error: 0.0510
    Epoch 361/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0057 - mean_absolute_error: 0.0393 - val_loss: 0.0170 - val_mean_absolute_error: 0.0534
    Epoch 362/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0063 - mean_absolute_error: 0.0409 - val_loss: 0.0217 - val_mean_absolute_error: 0.0520
    Epoch 363/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0069 - mean_absolute_error: 0.0405 - val_loss: 0.0182 - val_mean_absolute_error: 0.0530
    Epoch 364/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0089 - mean_absolute_error: 0.0447 - val_loss: 0.0187 - val_mean_absolute_error: 0.0574
    Epoch 365/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0048 - mean_absolute_error: 0.0381 - val_loss: 0.0228 - val_mean_absolute_error: 0.0571
    Epoch 366/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0064 - mean_absolute_error: 0.0433 - val_loss: 0.0216 - val_mean_absolute_error: 0.0554
    Epoch 367/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0073 - mean_absolute_error: 0.0417 - val_loss: 0.0171 - val_mean_absolute_error: 0.0512
    Epoch 368/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0057 - mean_absolute_error: 0.0391 - val_loss: 0.0166 - val_mean_absolute_error: 0.0507
    Epoch 369/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0051 - mean_absolute_error: 0.0383 - val_loss: 0.0150 - val_mean_absolute_error: 0.0483
    Epoch 370/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0039 - mean_absolute_error: 0.0341 - val_loss: 0.0145 - val_mean_absolute_error: 0.0468
    Epoch 371/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0040 - mean_absolute_error: 0.0338 - val_loss: 0.0178 - val_mean_absolute_error: 0.0545
    Epoch 372/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0082 - mean_absolute_error: 0.0425 - val_loss: 0.0129 - val_mean_absolute_error: 0.0477
    Epoch 373/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0050 - mean_absolute_error: 0.0363 - val_loss: 0.0305 - val_mean_absolute_error: 0.0755
    Epoch 374/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0156 - mean_absolute_error: 0.0576 - val_loss: 0.0172 - val_mean_absolute_error: 0.0517
    Epoch 375/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0056 - mean_absolute_error: 0.0408 - val_loss: 0.0169 - val_mean_absolute_error: 0.0523
    Epoch 376/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0069 - mean_absolute_error: 0.0379 - val_loss: 0.0153 - val_mean_absolute_error: 0.0503
    Epoch 377/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0068 - mean_absolute_error: 0.0414 - val_loss: 0.0173 - val_mean_absolute_error: 0.0506
    Epoch 378/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0050 - mean_absolute_error: 0.0364 - val_loss: 0.0154 - val_mean_absolute_error: 0.0511
    Epoch 379/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0050 - mean_absolute_error: 0.0382 - val_loss: 0.0155 - val_mean_absolute_error: 0.0509
    Epoch 380/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0063 - mean_absolute_error: 0.0397 - val_loss: 0.0169 - val_mean_absolute_error: 0.0493
    Epoch 381/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0058 - mean_absolute_error: 0.0395 - val_loss: 0.0269 - val_mean_absolute_error: 0.0603
    Epoch 382/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0163 - mean_absolute_error: 0.0522 - val_loss: 0.0280 - val_mean_absolute_error: 0.0587
    Epoch 383/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0114 - mean_absolute_error: 0.0543 - val_loss: 0.0204 - val_mean_absolute_error: 0.0573
    Epoch 384/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0074 - mean_absolute_error: 0.0438 - val_loss: 0.0172 - val_mean_absolute_error: 0.0508
    Epoch 385/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0075 - mean_absolute_error: 0.0434 - val_loss: 0.0223 - val_mean_absolute_error: 0.0569
    Epoch 386/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - loss: 0.0123 - mean_absolute_error: 0.0486 - val_loss: 0.0367 - val_mean_absolute_error: 0.0799
    Epoch 387/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0177 - mean_absolute_error: 0.0560 - val_loss: 0.0160 - val_mean_absolute_error: 0.0485
    Epoch 388/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0047 - mean_absolute_error: 0.0362 - val_loss: 0.0201 - val_mean_absolute_error: 0.0615
    Epoch 389/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0048 - mean_absolute_error: 0.0382 - val_loss: 0.0138 - val_mean_absolute_error: 0.0461
    Epoch 390/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - loss: 0.0062 - mean_absolute_error: 0.0402 - val_loss: 0.0129 - val_mean_absolute_error: 0.0508
    Epoch 391/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0078 - mean_absolute_error: 0.0429 - val_loss: 0.0131 - val_mean_absolute_error: 0.0506
    Epoch 392/1000
    50/50 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0067 - mean_absolute_error: 0.0414 - val_loss: 0.0145 - val_mean_absolute_error: 0.0465

    --- 모델 학습 완료 ---

    --- 테스트 데이터로 모델 성능을 평가합니다 ---
    테스트 데이터 손실 (MSE): 0.0108
    테스트 데이터 평균 절대 오차 (MAE): 0.0444
    16/16 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step 
    테스트 데이터 결정계수 (R²): 0.9888
    최적의 epoch: 372
    최소 val_loss: 0.01294
:::
![](/assets/images/vertopal_b595bfe9034e4266b1c860640658cdfd/76e0bf716051ddc4d5cc215f73a20506a4f88573.png)

![](/assets/images/vertopal_b595bfe9034e4266b1c860640658cdfd/cd054e145263738bd0eab39e17a3463fd2a3e5a9.png)

![](/assets/images/vertopal_b595bfe9034e4266b1c860640658cdfd/6b32c2a62c5c5c5989444671caa6df376528e8cb.png)

::: {.output .stream .stdout}

    === 최종 모델 성능 요약 ===
    모델 구조: 8-32-16-1
    활성화 함수: tanh
    최적 epoch: 372
    테스트 R²: 0.9888
    테스트 MAE: 0.0444
:::
:::

::: {#dd85a5a2 .cell .markdown}
밑에는 과거 코드들
:::
